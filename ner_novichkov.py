# -*- coding: utf-8 -*-
"""NER_Novichkov.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-lrMA6ctnHea82jsWPlNzvPWKiYjlEZ2

### **NER**

### spaCy vs Natasha

Загрузка всего необходимого
"""

!pip install natasha
!pip install datasets
!pip install spacy
!python -m spacy download ru_core_news_sm
!pip install tqdm

"""Загрузим необходимый датасет"""

from datasets import load_dataset
dataset = load_dataset("RCC-MSU/collection3")

"""### Напишем функции для обработки датасета:"""

from natasha import (Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger,
                     NewsSyntaxParser, NewsNERTagger,NamesExtractor,
                     PER, Doc, ORG, LOC)
import torch
import time
import spacy


# NATASHA
segmenter = Segmenter()
morph_vocab = MorphVocab()
emb = NewsEmbedding()
morph_tagger = NewsMorphTagger(emb)
syntax_parser = NewsSyntaxParser(emb)
ner_tagger = NewsNERTagger(emb)
names_extractor = NamesExtractor(morph_vocab)

# SPACY
# Загрузим предварительно обученную модель для русского языка
nlp = spacy.load("ru_core_news_sm")

names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC"]


def natasha_model(test_text):
  formatted_text = ' '.join(test_text)
  doc = Doc(formatted_text)
  doc.segment(segmenter)
  doc.tag_ner(ner_tagger)
  doc.tag_morph(morph_tagger)
  for token in doc.tokens:
    token.lemmatize(morph_vocab)
  doc.parse_syntax(syntax_parser)
  for span in doc.spans:
    span.normalize(morph_vocab)
  doc_spans = doc.spans
  result_list = [[span.type, span.text.replace(' ', '')] for span in doc_spans]
  return result_list


def spacy_model(test_text):
  formatted_text = ' '.join(test_text)
  # Обработаем текст с использованием spaCy
  doc = nlp(formatted_text)
  # Извлечем именованные сущности
  named_entities = [[ent.label_, ent.text] for ent in doc.ents]
  return named_entities

"""Протестируем модели и выясним их скорость"""

import time
test_text = ['Дополнение', ':', 'Д', '.', 'Медведев', 'присвоил', 'звания',
             'сотрудников', 'полиции', 'и', 'переназначил', '14',
             'руководителей', 'УВД', ',', 'ГУВД', 'и', 'МВД',
             'по', 'субъектам', 'РФ', '.']

start_natasha = time.time()
print(natasha_model(test_text))
finish_natasha = time.time()

start_spacy = time.time()
print(spacy_model(test_text))
finish_spacy = time.time()

time_natasha = finish_natasha - start_natasha
time_spacy = finish_spacy - start_spacy
print(time_natasha, time_spacy)

"""Предобработаем теги"""

tags_list = dataset["test"]["ner_tags"][0]
print(tags_list)
tokens = dataset["test"]["tokens"][0]
print(tokens)
names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC"]
tags = [names[tag] for tag in tags_list]
print(tags)

"""Возьмём тестовый датасет для дальнейшей работы"""

import pandas as pd

dataset_dict = {
    "ner_tags": dataset["test"]["ner_tags"],
    "tokens": dataset["test"]["tokens"]
}

df = pd.DataFrame(dataset_dict)

# Посмотрим на первые несколько строк в DataFrame
print(df.head())

names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC"]

for index, row in df.iterrows():
    tags = [names[tag] for tag in row["ner_tags"]]

    print(f"Example {index + 1}:")
    print("Tokens:", row["tokens"])
    print("Tags:", tags)
    print("\n")

names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC"]
df["tags"] = df["ner_tags"].apply(lambda tags: [names[tag] for tag in tags])

"""Очистим теги и оставим только самые необходимые:

*   LOC - location
*   PER - person
*   ORG - organization


"""

import pandas as pd

names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC"]

def process_row(row):
    tags_list = row["ner_tags"]
    tokens = row["tokens"]
    tags = [names[tag] for tag in tags_list]
    combined_entities = []
    current_entity = {"entity": None, "words": []}
    for token, tag in zip(tokens, tags):
        if tag.startswith("B-"):
            if current_entity["entity"] is not None:
                combined_entities.append(current_entity)
            current_entity = {"entity": tag[2:], "words": [token]}
        elif tag.startswith("I-"):
            if current_entity["entity"] is not None and tag[2:] == current_entity["entity"]:
                current_entity["words"].append(token)
            else:
                combined_entities.append(current_entity)
                current_entity = {"entity": tag[2:], "words": [token]}
        else:  # tag is "O"
            if current_entity["entity"] is not None:
                combined_entities.append(current_entity)
                current_entity = {"entity": None, "words": [token]}

    # Добавляем последнюю сущность в результат
    if current_entity["entity"] is not None:
        combined_entities.append(current_entity)
    # Формируем строку для нового столбца "clean_tags"
    clean_tags = []
    for entity in combined_entities:
        clean_tags.append([entity['entity'], ''.join(entity['words'])])
    return clean_tags

# Применяем функцию process_row к каждой строке и создаем новый столбец "clean_tags"
df["clean_tags"] = df.apply(process_row, axis=1)

# Выводим DataFrame с новым столбцом
df.head()

"""### Датасет подготовлен, теперь посмотрим, на что способны модели"""

from tqdm import tqdm

# Создаем пустой столбец "natasha" в DataFrame
df["natasha"] = None

# Используем tqdm для отслеживания прогресса
for i in tqdm(range(len(df))):
    df.at[i, "natasha"] = natasha_model(df.at[i, "tokens"])

# Создаем пустой столбец "spacy" в DataFrame
df["spacy"] = None

# Используем tqdm для отслеживания прогресса
for i in tqdm(range(len(df))):
    df.at[i, "spacy"] = spacy_model(df.at[i, "tokens"])

# Выводим DataFrame с новым столбцом
df

"""Вычислим первоначальную точность (берем целиком столбцы и сравниваем их). Данная точность не отобразит всю картину и не даст объективной оценки."""

def compare_columns_natasha(row):
    return row["clean_tags"] == row["natasha"]
# Применяем функцию и вычисляем процент совпадения
percentage_matching_n = df.apply(compare_columns_natasha, axis=1).mean() * 100

def compare_columns_spacy(row):
    return row["clean_tags"] == row["spacy"]
# Применяем функцию и вычисляем процент совпадения
percentage_matching_s = df.apply(compare_columns_spacy, axis=1).mean() * 100

print(f"Accuracy NATASHA: {percentage_matching_n}%")
print(f"Accuracy SPACY: {percentage_matching_s}%")

import pandas as pd

df['true_PER'] = 0
df['true_LOC'] = 0
df['true_ORG'] = 0

# Проходим по каждой строке DataFrame
for index, row in df.iterrows():
    # Проходим по каждой записи в clean_tags текущей строки
    for tag in row['clean_tags']:
        # Извлекаем тип и значение тега
        tag_type, tag_value = tag

        # Увеличиваем соответствующий счетчик в зависимости от типа тега
        if tag_type == 'PER':
            df.at[index, 'true_PER'] += 1
        elif tag_type == 'LOC':
            df.at[index, 'true_LOC'] += 1
        elif tag_type == 'ORG':
            df.at[index, 'true_ORG'] += 1

# Создаем столбцы с начальными значениями natasha
df['natasha_PER'] = 0
df['natasha_LOC'] = 0
df['natasha_ORG'] = 0

# Проходим по каждой строке DataFrame
for index, row in df.iterrows():
    # Проходим по каждой записи в clean_tags текущей строки
    for tag in row['natasha']:
        # Извлекаем тип и значение тега
        tag_type, tag_value = tag

        # Увеличиваем соответствующий счетчик в зависимости от типа тега
        if tag_type == 'PER':
            df.at[index, 'natasha_PER'] += 1
        elif tag_type == 'LOC':
            df.at[index, 'natasha_LOC'] += 1
        elif tag_type == 'ORG':
            df.at[index, 'natasha_ORG'] += 1

# Создаем столбцы с начальными значениями spacy
df['spacy_PER'] = 0
df['spacy_LOC'] = 0
df['spacy_ORG'] = 0

# Проходим по каждой строке DataFrame
for index, row in df.iterrows():
    # Проходим по каждой записи в clean_tags текущей строки
    for tag in row['spacy']:
        # Извлекаем тип и значение тега
        tag_type, tag_value = tag

        # Увеличиваем соответствующий счетчик в зависимости от типа тега
        if tag_type == 'PER':
            df.at[index, 'spacy_PER'] += 1
        elif tag_type == 'LOC':
            df.at[index, 'spacy_LOC'] += 1
        elif tag_type == 'ORG':
            df.at[index, 'spacy_ORG'] += 1

# Выводим получившийся DataFrame
df.head()

# Список типов тегов
tag_types = ['LOC', 'PER', 'ORG']

# Словарь для хранения совпадений по каждому типу тегов
match_counts = {tag: {'natasha': 0, 'spacy': 0} for tag in tag_types}

# Проходим по каждой строке DataFrame
for index, row in df.iterrows():
    for tag in tag_types:
        # Сравниваем значения в каждом столбце для natasha и spacy
        if row[f'true_{tag}'] == row[f'natasha_{tag}']:
            match_counts[tag]['natasha'] += 1
        if row[f'true_{tag}'] == row[f'spacy_{tag}']:
            match_counts[tag]['spacy'] += 1

# Общее количество строк
total_count = len(df)

# Рассчитываем точность для каждого типа тегов
accuracy = {tag: {tool: match_counts[tag][tool] / total_count for tool in ['natasha', 'spacy']} for tag in tag_types}

# Выводим значения точности
for tag in tag_types:
    print(f"Accuracy for natasha_{tag}: {accuracy[tag]['natasha']}")
    print(f"Accuracy for spacy_{tag}: {accuracy[tag]['spacy']}")

from sklearn.metrics import precision_score, recall_score, f1_score

# Ваши данные
true_PER = df["true_PER"]
true_LOC = df["true_LOC"]
true_ORG = df["true_ORG"]

natasha_PER = df["natasha_PER"]
natasha_LOC = df["natasha_LOC"]
natasha_ORG = df["natasha_ORG"]

spacy_PER = df["spacy_PER"]
spacy_LOC = df["spacy_LOC"]
spacy_ORG = df["spacy_ORG"]

# Функция для вычисления метрик и вывода результатов
def calculate_metrics(true_labels, predicted_labels):
    f1 = f1_score(true_labels, predicted_labels, average='micro')
    return f1

# Вычисление метрик для natasha
a = calculate_metrics(true_PER, natasha_PER)
b = calculate_metrics(true_LOC, natasha_LOC)
c = calculate_metrics(true_ORG, natasha_ORG)

# Вычисление метрик для spacy
d = calculate_metrics(true_PER, spacy_PER)
e = calculate_metrics(true_LOC, spacy_LOC)
f = calculate_metrics(true_ORG, spacy_ORG)

avg_natasha = (a + b + c) / 3
avg_spacy = (d + e + f) / 3
# Вывод усредненных значений
print(f'Average F1 Score_natasha: {avg_natasha}')
print(f'Average F1 Score_spacy: {avg_spacy}')

